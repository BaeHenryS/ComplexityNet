{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ad434d-91f1-4a9c-925a-794b1c56b865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0087bb4-c674-475f-940e-c90ae3917809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edbbdaf7-7851-444c-8f79-bdcfa1a1a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_create = client.files.create(\n",
    "  file=open(\"mbpp_chat_train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "val_create = client.files.create(\n",
    "  file=open(\"mbpp_chat_test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acf5b22c-7aed-4787-bf3e-d4e27511cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('file-O7XnrwQtEzmCuF1cwcrfISGf', 'file-USWsZglufSbxMH5XZFSQTvmo')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = train_create.id\n",
    "val_file = val_create.id\n",
    "training_file, val_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b40ebc87-b0b4-4f82-b155-9803ea3972de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_create = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file, \n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  # validation_file=val_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd069dc4-67fb-409e-99ff-479689b9326f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-kUs4WMZgRTprEYJbVuR83RRb', created_at=1700952965, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-C3Uef6f81pjJUiIQMtu8svVl', result_files=[], status='validating_files', trained_tokens=None, training_file='file-O7XnrwQtEzmCuF1cwcrfISGf', validation_file=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "661d817e-195d-4a05-a8d7-8aa41f6daa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-kUs4WMZgRTprEYJbVuR83RRb'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_job = ft_create.id\n",
    "ft_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14a3e11a-0210-46a0-bc5d-4ae20523a698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-kUs4WMZgRTprEYJbVuR83RRb', created_at=1700952965, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:personal::8OwzEA9b', finished_at=1700957308, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-C3Uef6f81pjJUiIQMtu8svVl', result_files=['file-l2R3W4egVuEo5rDzqkM2r2Nl'], status='succeeded', trained_tokens=261924, training_file='file-O7XnrwQtEzmCuF1cwcrfISGf', validation_file=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(ft_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2aab4eb-e3bf-4bbd-9456-b20a9726ed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:personal::8OwzEA9b'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ft_model = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model\n",
    "# ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59e59e2-afca-440d-8af8-82338252a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_gpt3_5_800 = \"ft:gpt-3.5-turbo-0613:personal::8OwzEA9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad09c06a-98c8-4e08-9d56-6348a9610d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f65f896-7aa5-48f8-9c74-f4fad35b1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model = ft_gpt3_5_800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7f43a3b-88b1-4795-8724-9626ab584d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '0']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"./mbpp_chat_test.jsonl\"\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    # Extract the 'prompt' field from each JSON object in the file and collect them into a list\n",
    "    messages = [json.loads(line)['messages'][:2] for line in file]\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    complexity = [json.loads(line)['messages'][2][\"content\"] for line in file]\n",
    "\n",
    "complexity[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1291456-5c6c-4fee-8d95-4a769c87a9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131ecef-96ae-4774-9808-4de824443466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5faeab96-7963-45cf-ba0f-c288fededf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'First, think step by step about the problem. Only after thinking thoroughly about the problem and showing your thinking process, output 0, 1, 2, or 3 based solely on the difficulty of creating the correct code for the task. Choose the least complex model that will solve the task accurately; avoid considering the time taken for solving. 0 represents a simpler task, 1 represents a slightly challenging task, 2 represents a moderately challenging task, and 3 represents a highly complex problem. Think step by step before outputting a number then output the number.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Write a python function to count the number of rotations required to generate a sorted array.'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "600d0bf4-deb1-474e-88ce-8c5a5998902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.chat.completions.create(\n",
    "                  model=ft_model,\n",
    "                  messages=messages[0],\n",
    "                  max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3c08a9d-40c1-43f0-8e97-5b066ec7835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60267d25-5fef-4208-ae3c-862427aa2e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped index: 173\n"
     ]
    }
   ],
   "source": [
    "og_model_res = []\n",
    "# ft_model_res = []\n",
    "ft_model_res = []\n",
    "# og_model_dav3_res = []\n",
    "\n",
    "for i, message in enumerate(messages):\n",
    "    try: \n",
    "        og_response = client.chat.completions.create(\n",
    "                      model=og_model,\n",
    "                      messages=message,\n",
    "                      max_tokens=500)\n",
    "        og_model_res.append(og_response.choices[0].message.content)\n",
    "        \n",
    "    except:\n",
    "        print(f\"skipped index: {i}\")\n",
    "        continue\n",
    "    # ft_response = client.chat.completions.create(\n",
    "    #               model=ft_model,\n",
    "    #               messages=message,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res.append(int(ft_response.choices[0].message.content))\n",
    "    \n",
    "    # ft_response2 = client.completions.create(\n",
    "    #               model=ft_model2,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res2.append(int(ft_response2.choices[0].text))\n",
    "    # ft_response3 = client.completions.create(\n",
    "    #               model=ft_model3,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res3.append(int(ft_response3.choices[0].text))\n",
    "    # og_dav3_response = client.completions.create(\n",
    "    #               model=og_model_dav3,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # og_model_dav3_res.append(int(og_dav3_response.choices[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25835919-5859-458d-ac83-302168d8f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 173)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complexity), len(og_model_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5bc9728-bd7a-43bf-b899-7c85355d9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complexity = complexity[:173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c5f6a8c-bbaa-4198-98cb-323f427913f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_last_integer(s):\n",
    "    # Find all groups of digits in the string\n",
    "    numbers = re.findall(r'\\d+', s)\n",
    "    # Return the last found number as an integer, or None if no numbers are found\n",
    "    return int(numbers[-1]) if numbers else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f2dd7-773b-46c4-b81a-922663c3b06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e316ea-444f-4cc6-913d-f69c454e6c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdd3291c-354c-495e-b637-1118845f0b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "7\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "\n",
    "for res in og_model_res:\n",
    "    print(find_last_integer(res))\n",
    "    ans.append(find_last_integer(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2f06e5c-062b-47b4-bb78-f3d6658ddad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 173)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complexity), len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "410cd9cc-f76d-4433-aa16-73966a1ecbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og</th>\n",
       "      <th>og_correctness</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     og  og_correctness ground_truth\n",
       "0     1           False            0\n",
       "1     1            True            1\n",
       "2     0            True            0\n",
       "3     1            True            1\n",
       "4     2           False            0\n",
       "..   ..             ...          ...\n",
       "168   0            True            0\n",
       "169   2            True            2\n",
       "170   0            True            0\n",
       "171   0            True            0\n",
       "172   1            True            1\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Creating correctness columns\n",
    "og_correctness = [l1 == int(gt) for l1, gt in zip(ans, complexity[:173])]\n",
    "# ft_correctness = [l2 == int(gt) for l2, gt in zip(ft_model_res, complexity[:173])]\n",
    "# ft_correctness2 = [l3 == int(gt) for l3, gt in zip(ft_model_res2, complexity)]\n",
    "# ft_correctness3 = [l4 == int(gt) for l4, gt in zip(ft_model_res3, complexity)]\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    # 'prompt': prompts,\n",
    "    'og': ans,\n",
    "    'og_correctness': og_correctness,\n",
    "    # 'ft': ft_model_res,\n",
    "    # 'ft_correctness': ft_correctness,\n",
    "    # 'ft2': ft_model_res2,\n",
    "    # 'ft_correctness2': ft_correctness2,\n",
    "    # 'ft3': ft_model_res3,\n",
    "    # 'ft_correctness3': ft_correctness3,\n",
    "    'ground_truth': complexity[:173],\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f038fe78-4857-4ac8-8d5e-2be90b7bdc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ft_true_count2 = df['ft_correctness2'].sum()\n",
    "og_true_count = df['og_correctness'].sum() \n",
    "# ft_true_count = df['ft_correctness'].sum()\n",
    "# ft_true_count3 = df['ft_correctness3'].sum()\n",
    "og_true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0e1e7c4-fd03-43a2-a2d7-84ef737094f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"./test_results_chat_4classes.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ad9749-2851-4383-acc3-7a4f9368c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model_dav2_res = ft_model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07e28a7-9994-47ea-82f0-de5b1e0ede2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# og_model_dav2_res = og_model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea84f5-561c-46bd-a785-4bbefc61f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
