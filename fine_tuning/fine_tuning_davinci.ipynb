{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKXNRHBiTL7c",
        "outputId": "7d791f99-ebd0-428f-e942-fad4b47f92b3"
      },
      "id": "nKXNRHBiTL7c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.8)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0087bb4-c674-475f-940e-c90ae3917809",
      "metadata": {
        "id": "c0087bb4-c674-475f-940e-c90ae3917809"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths for output files\n",
        "output_file_1 = \"./5class_train.jsonl\"\n",
        "output_file_2 = \"./5class_val.jsonl\"\n",
        "output_file_3 = \"./5class_test.jsonl\"\n",
        "\n",
        "# Path to the input JSONL file\n",
        "input_file_path = \"./mbpp_test_5class_completion.jsonl\"\n",
        "\n",
        "# Read the input file and divide into sections\n",
        "with open(input_file_path, 'r') as file:\n",
        "    # Read lines from the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "    # test-train-validation split #1\n",
        "    # section_1 = lines[:120]\n",
        "    # section_2 = lines[120:140]\n",
        "    # section_3 = lines[140:174]\n",
        "\n",
        "    # test-train-validation split #2\n",
        "    # section_1 = lines[170:] + lines[10:40] + lines[60:90] + lines[100:150] + lines[154:160]\n",
        "    # section_2 = lines[90:100] + lines[160:170]\n",
        "    # section_3 = lines[40:60] + lines[0:10] + lines[150:154]\n",
        "\n",
        "    # test-train-validation split #3\n",
        "    # section_1 = lines[:80] + lines[134:]\n",
        "    # section_2 = lines[80:100]\n",
        "    # section_3 = lines[100:134]\n",
        "\n",
        "    # test-train-validation split #4\n",
        "    # section_1 = lines[0:116] + lines[150:154]\n",
        "    # section_2 = lines[154:174]\n",
        "    # section_3 = lines[116:150]\n",
        "\n",
        "    # # line breakup 5\n",
        "    section_1 = lines[170:] + lines[10:40] + lines[50:60] + lines[70:100] + lines[110:150] + lines[154:160]\n",
        "    section_2 = lines[100:110] + lines[160:170]\n",
        "    section_3 = lines[40:50] + lines[60:70] + lines[0:10] + lines[150:154]\n",
        "\n",
        "\n",
        "# Write each section to different output files\n",
        "with open(output_file_1, 'w') as file:\n",
        "    file.writelines(section_1)\n",
        "\n",
        "with open(output_file_2, 'w') as file:\n",
        "    file.writelines(section_2)\n",
        "\n",
        "with open(output_file_3, 'w') as file:\n",
        "    file.writelines(section_3)\n"
      ],
      "metadata": {
        "id": "XWu0f5pROvor"
      },
      "id": "XWu0f5pROvor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbbdaf7-7851-444c-8f79-bdcfa1a1a6a9",
      "metadata": {
        "id": "edbbdaf7-7851-444c-8f79-bdcfa1a1a6a9"
      },
      "outputs": [],
      "source": [
        "train_create = client.files.create(\n",
        "  file=open(\"5class_train.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "val_create = client.files.create(\n",
        "  file=open(\"5class_val.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf5b22c-7aed-4787-bf3e-d4e27511cc14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acf5b22c-7aed-4787-bf3e-d4e27511cc14",
        "outputId": "d3548760-076e-4dad-8c74-1055e1721389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('file-Br6tuKi7lJRidRf13nWaJzw3', 'file-14Cbsbn0moWDo7Wi839aKW7b')"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ],
      "source": [
        "training_file = train_create.id\n",
        "val_file = val_create.id\n",
        "training_file, val_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40ebc87-b0b4-4f82-b155-9803ea3972de",
      "metadata": {
        "id": "b40ebc87-b0b4-4f82-b155-9803ea3972de"
      },
      "outputs": [],
      "source": [
        "ft_create = client.fine_tuning.jobs.create(\n",
        "  training_file=training_file,\n",
        "  model=\"davinci-002\",\n",
        "  validation_file=val_file,\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":4\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd069dc4-67fb-409e-99ff-479689b9326f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd069dc4-67fb-409e-99ff-479689b9326f",
        "outputId": "2b40bc99-7502-4e48-81f9-5b56ab34e28e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-gu9lfNcVgpFaCPFCYVP8QJYB', created_at=1702171860, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=4, batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-fZi42eOEIp1JEC3Y4sRGr0Aj', result_files=[], status='validating_files', trained_tokens=None, training_file='file-vBiWprlmsiK4PPjBu6xq5qnS', validation_file='file-sxvJORBSLJLvUqMUJjfOXDgo')"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ],
      "source": [
        "ft_create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "661d817e-195d-4a05-a8d7-8aa41f6daa0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "661d817e-195d-4a05-a8d7-8aa41f6daa0f",
        "outputId": "5bbab512-4556-4122-9a2a-2daf066c7477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-gu9lfNcVgpFaCPFCYVP8QJYB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "ft_job = ft_create.id\n",
        "ft_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a3e11a-0210-46a0-bc5d-4ae20523a698",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14a3e11a-0210-46a0-bc5d-4ae20523a698",
        "outputId": "26fefad3-0284-47bd-920f-15afc6f2bb95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-gu9lfNcVgpFaCPFCYVP8QJYB', created_at=1702171860, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=4, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-fZi42eOEIp1JEC3Y4sRGr0Aj', result_files=[], status='validating_files', trained_tokens=None, training_file='file-vBiWprlmsiK4PPjBu6xq5qnS', validation_file='file-sxvJORBSLJLvUqMUJjfOXDgo')"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "client.fine_tuning.jobs.retrieve(ft_job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2aab4eb-e3bf-4bbd-9456-b20a9726ed4d",
      "metadata": {
        "id": "c2aab4eb-e3bf-4bbd-9456-b20a9726ed4d"
      },
      "outputs": [],
      "source": [
        "ft_model = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model"
      ],
      "metadata": {
        "id": "8vzBAc_LWoTe"
      },
      "id": "8vzBAc_LWoTe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66843367-04d2-4fed-be68-a8c32311e563",
      "metadata": {
        "id": "66843367-04d2-4fed-be68-a8c32311e563"
      },
      "outputs": [],
      "source": [
        "response = client.completions.create(\n",
        "  model=ft_model,\n",
        "  prompt= \"On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task 'Write a function to find whether all the given tuples have equal length or not.' is: \",\n",
        "  max_tokens=1\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad09c06a-98c8-4e08-9d56-6348a9610d68",
      "metadata": {
        "id": "ad09c06a-98c8-4e08-9d56-6348a9610d68"
      },
      "outputs": [],
      "source": [
        "og_model = \"davinci-002\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f3c25d-7eea-4d6b-b88d-ffbf38714c37",
      "metadata": {
        "id": "41f3c25d-7eea-4d6b-b88d-ffbf38714c37"
      },
      "outputs": [],
      "source": [
        "og_model_dav3 = \"text-davinci-003\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad9f194-e867-45a5-a01d-e366411d3b59",
      "metadata": {
        "id": "bad9f194-e867-45a5-a01d-e366411d3b59"
      },
      "outputs": [],
      "source": [
        "ft_model2 = \"ft:davinci-002:personal::8OhPdNGc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3860c647-3dc9-451f-b9bb-556ffc48ce78",
      "metadata": {
        "id": "3860c647-3dc9-451f-b9bb-556ffc48ce78"
      },
      "outputs": [],
      "source": [
        "ft_model_full_4classes = \"ft:davinci-002:personal::8Otpm6EB\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0c23c5-2eda-4076-b48c-dfcbb6a79860",
      "metadata": {
        "id": "ce0c23c5-2eda-4076-b48c-dfcbb6a79860"
      },
      "outputs": [],
      "source": [
        "ft_model3 = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7934a74-7108-4ddb-a212-e8d5d0a549f8",
      "metadata": {
        "id": "b7934a74-7108-4ddb-a212-e8d5d0a549f8"
      },
      "outputs": [],
      "source": [
        "ft_model_full_3classes = \"ft:davinci-002:personal::8Ov33dCP\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_model = \"ft:davinci-002:personal::8PG1EyV1\""
      ],
      "metadata": {
        "id": "oUJnZEavjtD6"
      },
      "id": "oUJnZEavjtD6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_model_5class = \"ft:davinci-002:personal::8RnK5q91\""
      ],
      "metadata": {
        "id": "MtpO4fU6dOll"
      },
      "id": "MtpO4fU6dOll",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_5class_new = \"ft:davinci-002:personal::8S0R06FX\""
      ],
      "metadata": {
        "id": "vCsMsseNXevT"
      },
      "id": "vCsMsseNXevT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury5class_new_complexity = \"ft:davinci-002:personal::8S11axsW\""
      ],
      "metadata": {
        "id": "QnBDl5nCcBHg"
      },
      "id": "QnBDl5nCcBHg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_model_4class_dist = \"ft:davinci-002:personal::8RzllpS9\""
      ],
      "metadata": {
        "id": "cRt3CsadH8ai"
      },
      "id": "cRt3CsadH8ai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_model_2 = \"ft:davinci-002:personal::8S6TmYPd\""
      ],
      "metadata": {
        "id": "i7JLydCSwDoq"
      },
      "id": "i7JLydCSwDoq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_model_messing = \"ft:davinci-002:personal::8S6noJ0d\""
      ],
      "metadata": {
        "id": "5bZwEqRo08Pf"
      },
      "id": "5bZwEqRo08Pf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_model_3 = \"ft:davinci-002:personal::8Tz4B0J2\""
      ],
      "metadata": {
        "id": "BbgwoW62UvAG"
      },
      "id": "BbgwoW62UvAG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_model_1 = \"ft:davinci-002:personal::8TyUZITb\""
      ],
      "metadata": {
        "id": "k3NouZ-CWJ-P"
      },
      "id": "k3NouZ-CWJ-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_model_4 = \"ft:davinci-002:personal::8TzC7TEG\""
      ],
      "metadata": {
        "id": "k9YWQfwtfId9"
      },
      "id": "k9YWQfwtfId9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_model_5 = \"ft:davinci-002:personal::8TzVwJFs\""
      ],
      "metadata": {
        "id": "y7wEQ5KYfLCU"
      },
      "id": "y7wEQ5KYfLCU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_NEW_1 = \"ft:davinci-002:personal::8U30Rpcm\""
      ],
      "metadata": {
        "id": "jAyyfcSYV3DZ"
      },
      "id": "jAyyfcSYV3DZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_NEW_2 = \"ft:davinci-002:personal::8U3Wv6wf\""
      ],
      "metadata": {
        "id": "Xdayesc7fJxF"
      },
      "id": "Xdayesc7fJxF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_NEW_3 = \"ft:davinci-002:personal::8U3ip1tK\""
      ],
      "metadata": {
        "id": "_RkTpfH4mbb1"
      },
      "id": "_RkTpfH4mbb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_NEW_4 = \"ft:davinci-002:personal::8U4Hps37\""
      ],
      "metadata": {
        "id": "V5w5XkbKp1ba"
      },
      "id": "V5w5XkbKp1ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fleury_174_NEW_5 = \"ft:davinci-002:personal::8U6hkoKq\""
      ],
      "metadata": {
        "id": "W2TLqSCLp1tV"
      },
      "id": "W2TLqSCLp1tV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f43a3b-88b1-4795-8724-9626ab584d8f",
      "metadata": {
        "id": "b7f43a3b-88b1-4795-8724-9626ab584d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0638f18d-a3d4-45c6-b9fa-ee380e45843e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the volume of a triangular prism.\" is: ',\n",
              " 'On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to check that the given string contains only a certain set of characters(in this case a-z, a-z and 0-9) by using regex.\" is: ',\n",
              " 'On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to count numbers whose oth and nth bits are set.\" is: ',\n",
              " 'On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the sum of fourth power of n natural numbers.\" is: ',\n",
              " 'On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to perform the concatenation of two string tuples.\" is: ']"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def extract_after_complexity(input_string):\n",
        "    complexity_start = input_string.find(\"complexity of the task\")\n",
        "    if complexity_start != -1:\n",
        "        return input_string[complexity_start + len(\"complexity of the task\"):]\n",
        "    return None\n",
        "\n",
        "prompt_str = \"Assess the coding complexity on a scale of 0 to 2, where 0 implies a straightforward task, 1 denotes moderate complexity, and 2 signifies a highly intricate problem. Evaluate the coding complexity specifically for the task of:\"\n",
        "\n",
        "input_file_path = \"./5class_test.jsonl\"\n",
        "\n",
        "with open(input_file_path, 'r') as file:\n",
        "    # Extract the 'prompt' field from each JSON object in the file and collect them into a list\n",
        "    prompts = [json.loads(line)['prompt'] for line in file]\n",
        "\n",
        "with open(input_file_path, 'r') as file:\n",
        "    complexity = [json.loads(line)['completion'] for line in file]\n",
        "\n",
        "prompts[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60267d25-5fef-4208-ae3c-862427aa2e11",
      "metadata": {
        "id": "60267d25-5fef-4208-ae3c-862427aa2e11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be0767f-99d2-4f2c-d4fd-8edeec165664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find t-nth term of geometric series.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the largest number that can be formed with the given digits.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to check whether the given two integers have opposite sign or not.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the nth octagonal number.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the maximum length of the subsequence with difference between adjacent elements for the given array.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to count number of substrings with the sum of digits equal to their length.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find smallest number in a list.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the maximum difference between available pairs in the given tuple list.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to sort a list of tuples using lambda.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to count positive numbers in a list.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the volume of a sphere.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the n-th number in newman conway sequence.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the surface area of a sphere.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find nth centered hexagonal number.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to get the frequency of the elements in a list.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the closest smaller number than n.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the length of the longest word.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to check if a substring is present in a given list of string values.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to check whether the given number is undulating or not.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to calculate the value of 'a' to the power 'b'.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to identify non-prime numbers.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the largest integers from a given list of numbers using heap queue algorithm.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find the number of ways to fill it with 2 x 1 dominoes for the given 3 x n board.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find all words which are at least 4 characters long in a string by using regex.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to find squares of individual elements in a list using lambda function.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the minimum number of rotations required to get the same string.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to get the n smallest items from a dataset.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to remove first and last occurrence of a given character from the string.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to sort a given matrix in ascending order according to the sum of its rows.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the volume of a triangular prism.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to check that the given string contains only a certain set of characters(in this case a-z, a-z and 0-9) by using regex.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to count numbers whose oth and nth bits are set.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a python function to find the sum of fourth power of n natural numbers.\" is: \n",
            "On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents a medium difficulty task, 4 represents a challenging task, and 5 represents a highly complex problem, the complexity of the task \"Write a function to perform the concatenation of two string tuples.\" is: \n"
          ]
        }
      ],
      "source": [
        "og_model_res = []\n",
        "ft_model_res = []\n",
        "ft_model_res2 = []  # Assuming this was meant to be another list\n",
        "og_model_dav3_res = []\n",
        "\n",
        "for prompt in prompts:\n",
        "    # Commented out code for original model and other fine-tuned models\n",
        "    # Fetching probabilities for the Fleury model\n",
        "    print(prompt)\n",
        "    ft_arr = []\n",
        "    for _ in range(5):\n",
        "\n",
        "      ft_response = client.completions.create(\n",
        "                      model=fleury_174_NEW_5,\n",
        "                      prompt=prompt,\n",
        "                      max_tokens=1,\n",
        "                      logprobs=100  # Requesting log probabilities for better insight\n",
        "      )\n",
        "      ft_arr.append({\n",
        "          \"text\": prompt,\n",
        "          \"response\": int(ft_response.choices[0].text),\n",
        "          \"logprobs\": ft_response.choices[0].logprobs   # Accessing log probabilities\n",
        "      })\n",
        "    ft_model_res.append(ft_arr)\n",
        "\n",
        "    # Fetching probabilities for the original Davinci model\n",
        "    og_arr = []\n",
        "    for _ in range(5):\n",
        "      og_dav3_response = client.completions.create(\n",
        "                          model=og_model,\n",
        "                          prompt=prompt,\n",
        "                          max_tokens=1,\n",
        "                          logprobs=100  # Requesting log probabilities\n",
        "      )\n",
        "      og_arr.append({\n",
        "          \"text\": prompt,\n",
        "          \"response\": int(og_dav3_response.choices[0].text),\n",
        "          \"logprobs\": og_dav3_response.choices[0].logprobs  # Accessing log probabilities\n",
        "      })\n",
        "    og_model_dav3_res.append(og_arr)\n",
        "\n",
        "    # Similar logic for other models if required\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAx0lNvv-nk_"
      },
      "id": "CAx0lNvv-nk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25835919-5859-458d-ac83-302168d8f3e5",
      "metadata": {
        "id": "25835919-5859-458d-ac83-302168d8f3e5",
        "outputId": "460e8af9-4e2f-4a60-bde8-0d98bf6df211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "len(complexity)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_dav3_response"
      ],
      "metadata": {
        "id": "8QJd7XU-2sIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a5b652-3543-4c7e-aa8c-4c55ce8b4b4a"
      },
      "id": "8QJd7XU-2sIu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Completion(id='cmpl-8U3En8D0LIeFL2gn7i4nZgCARzr6h', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=Logprobs(text_offset=[413], token_logprobs=[-1.228918], tokens=['3'], top_logprobs=[{'3': -1.228918, '4': -1.197668, '2': -1.713293, '5': -2.2211056, '1': -2.3617306}]), text='3')], created=1702172977, model='davinci-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=87, total_tokens=88))"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410cd9cc-f76d-4433-aa16-73966a1ecbfd",
      "metadata": {
        "id": "410cd9cc-f76d-4433-aa16-73966a1ecbfd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Creating correctness columns\n",
        "print([l1 for l1 in ft_model_res])\n",
        "# og_correctness = [l1['response'] == int(gt) or l1['response'] == int(gt) - 1 or l1['response'] == int(gt) + 1 for l1, gt in zip(og_model_dav3_res, complexity)]\n",
        "og_responses =[[item['response'] for item in l1] for l1, gt in zip(og_model_dav3_res, complexity)]\n",
        "# ft_correctness_true = [l2['response'] == int(gt) for l2, gt in zip(ft_model_res, complexity)]\n",
        "# ft_correctness = [l2['response'] == int(gt) or l2['response'] == int(gt) - 1 or l2['response'] == int(gt) + 1 for l2, gt in zip(ft_model_res, complexity)]\n",
        "# ft_greater = [l2['response'] > int(gt) for l2, gt in zip(ft_model_res, complexity)]\n",
        "# ft_less = [l2['response'] < int(gt) for l2, gt in zip(ft_model_res, complexity)]\n",
        "# ft_3_5_less = [((l2['response'] == int(gt) - 1 and int(gt) == 4) or int(gt) == 2) for l2, gt in zip(ft_model_res, complexity)]\n",
        "responses = [[item['response'] for item in l2] for l2, gt in zip(ft_model_res, complexity)]\n",
        "# ft_correctness2 = [l3 == int(gt) for l3, gt in zip(ft_model_res2, complexity)]\n",
        "# ft_correctness3 = [l4 == int(gt) for l4, gt in zip(ft_model_res3, complexity)]\n",
        "\n",
        "# Creating the DataFrame\n",
        "df = pd.DataFrame({\n",
        "    # 'prompt': prompts,\n",
        "    'complexity': complexity,\n",
        "    'fine_tuned_responses': responses,\n",
        "    'og_responses': og_responses,\n",
        "    # 'og_correctness': og_correctness,\n",
        "    # 'ft_correctness': ft_correctness\n",
        "    # 'og': og_model_res,\n",
        "    # 'og_response': og_model_dav3_res,\n",
        "    # 'ft_response': ft_model_res,\n",
        "    # 'ft_greater': ft_greater,\n",
        "    # 'ft_less': ft_less,\n",
        "    # 'ft': ft_model_res,\n",
        "    # 'ft_correctness_true': ft_correctness_true,\n",
        "    # 'ft_correctness': ft_correctness,\n",
        "    # 'ft_3_5_less': ft_3_5_less\n",
        "    # 'ft2': ft_model_res2,\n",
        "    # 'ft_correctness2': ft_correctness2,\n",
        "    # 'ft3': ft_model_res3,\n",
        "    # 'ft_correctness3': ft_correctness3,\n",
        "    # 'ground_truth': complexity,\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "bB2KfjQrZ19w"
      },
      "id": "bB2KfjQrZ19w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUwRA31gZuvA"
      },
      "id": "wUwRA31gZuvA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f038fe78-4857-4ac8-8d5e-2be90b7bdc06",
      "metadata": {
        "id": "f038fe78-4857-4ac8-8d5e-2be90b7bdc06",
        "outputId": "f4757b81-486d-4444-ad87-94e942620b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 26\n"
          ]
        }
      ],
      "source": [
        "# ft_true_count2 = df['ft_correctness2'].sum()\n",
        "og_true_count = df['og_correctness'].sum()\n",
        "ft_true_count = df['ft_correctness'].sum()\n",
        "# ft_count_actual = df['ft_correctness_true'].sum()\n",
        "# greater = df['ft_greater'].sum()\n",
        "# less = df['ft_less'].sum()\n",
        "# ft_3_5_less = df['ft_3_5_less'].sum()\n",
        "# # ft_true_count3 = df['ft_correctness3'].sum()\n",
        "# print(less, greater, ft_3_5_less)\n",
        "# print(ft_count_actual, ft_true_count)\n",
        "print(og_true_count, ft_true_count)\n",
        "# , og_true_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(model, complexity_arr):\n",
        "  arr = []\n",
        "  for l1, gt in zip(model, complexity_arr):\n",
        "    i = 0\n",
        "    for elt in l1['logprobs']:\n",
        "      i += 1\n",
        "      if i != 4:\n",
        "        continue\n",
        "      else:\n",
        "        i = 0\n",
        "        try:\n",
        "          arr.append(elt[1][0][str(int(gt))])\n",
        "        except:\n",
        "          continue\n",
        "  return sum(arr) / len(arr), arr\n",
        "print(get_loss(ft_model_res, complexity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh2zEdMVzfST",
        "outputId": "e1c0d4f3-1146-41c5-97bb-4a62a83086cd"
      },
      "id": "fh2zEdMVzfST",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-3.4427566922432353, [-0.00063464424, -3.9884238, -0.38498148, -0.0048199417, -5.0696616, -0.011895887, -0.002470402, -0.0004909753, -0.00062802393, -6.643229, -0.0039356505, -8.774017, -0.03779641, -0.0034569246, -5.403624, -9.117791, -8.680275, -8.133395, -0.0037840286, -6.650473, -8.524179, -0.0086517, -0.0006656601, -1.5784204, -0.0065148463, -6.833746, -10.773902, -0.006166342, -7.8312364, -0.12589432, -6.190352, -0.1555131, -2.711506, -9.391196])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e1e7c4-fd03-43a2-a2d7-84ef737094f8",
      "metadata": {
        "id": "b0e1e7c4-fd03-43a2-a2d7-84ef737094f8"
      },
      "outputs": [],
      "source": [
        "df.to_json(\"./test_results_3classes.jsonl\", orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ad9749-2851-4383-acc3-7a4f9368c57b",
      "metadata": {
        "id": "52ad9749-2851-4383-acc3-7a4f9368c57b"
      },
      "outputs": [],
      "source": [
        "# ft_model_dav2_res = ft_model_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07e28a7-9994-47ea-82f0-de5b1e0ede2b",
      "metadata": {
        "id": "f07e28a7-9994-47ea-82f0-de5b1e0ede2b"
      },
      "outputs": [],
      "source": [
        "# og_model_dav2_res = og_model_res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_file_path = './mbpp_label_refined_no_zero_complexity.jsonl'  # Path to the provided JSONL file\n",
        "output_file_path = './mbpp_test_5class_completion.jsonl'  # Path for the output JSONL file\n",
        "\n",
        "# Read the JSONL file\n",
        "with open(input_file_path, 'r') as file:\n",
        "    current_data = [json.loads(line) for line in file]\n",
        "\n",
        "# Perform the transformation\n",
        "transformed_data = []\n",
        "\n",
        "for item in current_data:\n",
        "    transformed_entry = {\n",
        "        \"prompt\": f\"On a scale of 1 to 5 based solely on the complexity of creating the correct code for the task, \"\n",
        "                  f\"where 1 represents a very easy task, 2 represents a fairly straightforward task, and 3 represents \"\n",
        "                  f\"a medium difficulty task, 4 represents a challenging task, and 5 represents \"\n",
        "                  f\"a highly complex problem, the complexity of the task \\\"{item['text']}\\\" is: \",\n",
        "        \"completion\": str(item[\"complexity\"])\n",
        "    }\n",
        "    transformed_data.append(transformed_entry)\n",
        "\n",
        "# Write the transformed data to a new JSONL file\n",
        "with open(output_file_path, 'w') as outfile:\n",
        "    for entry in transformed_data:\n",
        "        json_record = json.dumps(entry)\n",
        "        outfile.write(f\"{json_record}\\n\")"
      ],
      "metadata": {
        "id": "ZNh4L8AN-vAz"
      },
      "id": "ZNh4L8AN-vAz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paradigm(llama, gpt3, gpt4):\n",
        "  llama_const = 1\n",
        "  gpt3_const = 1\n",
        "  gpt4_const = 1\n",
        "  return llama_const * llama + gpt3_const * gpt3 + gpt4_const * gpt4"
      ],
      "metadata": {
        "id": "7pHfa5Pi9V1v"
      },
      "id": "7pHfa5Pi9V1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = 'mbpp_label_no_zero.jsonl'\n",
        "global_arr = []\n",
        "with open(input_file_path, 'r') as file:\n",
        "    prompts = [(json.loads(line)['text'], json.loads(line)['code_llama_success'], json.loads(line)['method2_gpt3_5_success'], json.loads(line)['method2_gpt4_success'], json.loads(line)['complexity']) for line in file]\n",
        "# with open(input_file_path, 'r') as file:\n",
        "#     prompts = [json.loads(line)['completion'] for line in file]\n",
        "for prompt in prompts:\n",
        "  global_arr.append(paradigm(prompt[1], prompt[2], prompt[3]))\n",
        "  print(prompt)"
      ],
      "metadata": {
        "id": "Kx6gd0LO81rs"
      },
      "id": "Kx6gd0LO81rs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the complexity function\n",
        "def get_complexity(obj):\n",
        "    llama_num = obj['code_llama_success']\n",
        "    gpt3_num = obj['method2_gpt3_5_success']\n",
        "    gpt4_num = obj['method2_gpt4_success']\n",
        "    sum = paradigm(llama_num, gpt3_num, gpt4_num)\n",
        "    if (llama_num + gpt3_num >= 7) or llama_num == 5:\n",
        "        return 1\n",
        "    elif gpt3_num == 5:\n",
        "        return 2\n",
        "    elif gpt4_num == 5:\n",
        "        return 3\n",
        "    elif gpt4_num >= 2 or gpt3_num == 2:\n",
        "        return 4\n",
        "    else:\n",
        "      return 5\n",
        "\n",
        "    # NEW ONE BELOW\n",
        "    # if (llama_num + gpt3_num >= 7) or llama_num >= 4:\n",
        "    #     return 1\n",
        "    # elif (llama_num == 2 or llama_num == 3) and (gpt3_num == 5) or llama_num > gpt3_num or llama_num > gpt4_num or sum >= 11:\n",
        "    #     return 2\n",
        "    # elif ((gpt3_num == 2 or gpt3_num == 3) and (gpt4_num == 4 or gpt4_num == 5)) or gpt3_num > gpt4_num:\n",
        "    #     return 3\n",
        "    # elif sum >= 7:\n",
        "    #     return 4\n",
        "    # else:\n",
        "    #   return 5\n",
        "    # if llama_num in [2, 3, 4, 5]:\n",
        "    #     return 1\n",
        "    # elif sum >= 10:\n",
        "    #     return 2\n",
        "    # elif gpt3_num > gpt4_num or llama_num > gpt3_num or llama_num > gpt4_num:\n",
        "    #     return 3\n",
        "    # elif sum >= 7:\n",
        "    #     return 4\n",
        "    # else:\n",
        "    #     return 5"
      ],
      "metadata": {
        "id": "gjbs2p0y8yhY"
      },
      "id": "gjbs2p0y8yhY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Path to the input JSONL file\n",
        "input_file_path = \"./mbpp_label_no_zero.jsonl\"\n",
        "file3_path = \"./mbpp_label_refined_no_zero_complexity.jsonl\"\n",
        "\n",
        "# Read the input file and process each line\n",
        "with open(input_file_path, 'r') as file:\n",
        "    # Read lines from the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "    # Process each line\n",
        "    for index, line in enumerate(lines):\n",
        "        # Load JSON object from the line\n",
        "        data = json.loads(line)\n",
        "\n",
        "        # Append 'complexity' key with the associated value\n",
        "        data['complexity'] = get_complexity(data)\n",
        "\n",
        "        # Update the line with the appended 'complexity' key\n",
        "        lines[index] = json.dumps(data) + '\\n'\n",
        "\n",
        "# Write the updated content back to the file\n",
        "with open(file3_path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "4Bl65XEM_n2R"
      },
      "id": "4Bl65XEM_n2R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Path to the input JSONL file\n",
        "input_file_path = \"./mbpp_label_refined_all.jsonl\"\n",
        "output_file_path = \"./mbpp_label_refined_no_zero.jsonl\"\n",
        "\n",
        "# Read the input file and filter rows\n",
        "with open(input_file_path, 'r') as file:\n",
        "    # Read lines from the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "    # Filter rows where all three keys have a value of 0\n",
        "    filtered_lines = [line for line in lines if json.loads(line).get('code_llama_success', 0) != 0\n",
        "                      or json.loads(line).get('method2_gpt3_5_success', 0) != 0\n",
        "                      or json.loads(line).get('method2_gpt4_success', 0) != 0]\n",
        "\n",
        "# Write the filtered content back to the file\n",
        "with open(output_file_path, 'w') as file:\n",
        "    file.writelines(filtered_lines)\n"
      ],
      "metadata": {
        "id": "P2EZ4WYxDyF3"
      },
      "id": "P2EZ4WYxDyF3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Paths to the input files\n",
        "file2_path = \"./mbpp_label_refined_gpt3_4_238.jsonl\"\n",
        "file1_path = \"./mbpp_label_refined_llama238.jsonl\"\n",
        "file3_path = \"./mbpp_test_5class_completion.jsonl\"\n",
        "\n",
        "# Open both files for reading and writing\n",
        "with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
        "    # Read lines from both files\n",
        "    lines_file1 = file1.readlines()\n",
        "    lines_file2 = file2.readlines()\n",
        "\n",
        "    # Iterate through each line in both files\n",
        "    for index, line_file1 in enumerate(lines_file1):\n",
        "        # Extract the 'code_llama_success' property from file1\n",
        "        data = json.loads(line_file1)\n",
        "        code_llama_success = data.get('code_llama_success')\n",
        "\n",
        "        # Update the corresponding line in file2 with 'code_llama_success' from file1\n",
        "        data_file2 = json.loads(lines_file2[index])\n",
        "        data_file2['code_llama_success'] = code_llama_success\n",
        "        lines_file2[index] = json.dumps(data_file2) + '\\n'\n",
        "\n",
        "# Write the updated content back to file2\n",
        "with open(file3_path, 'w') as file2:\n",
        "    file2.writelines(lines_file2)"
      ],
      "metadata": {
        "id": "ic-NIp3hlb5w"
      },
      "id": "ic-NIp3hlb5w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data (replace this with your array of integers)\n",
        "data = global_arr  # Replace this with your array of integers\n",
        "\n",
        "# Create a histogram\n",
        "plt.hist(data, bins=10, alpha=0.7, color='blue')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Integer Data')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Calculate summary statistics\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "std_dev = np.std(data)\n",
        "min_val = np.min(data)\n",
        "max_val = np.max(data)\n",
        "mode_val = stats.mode(data)\n",
        "\n",
        "twenty = np.percentile(data, 20)\n",
        "forty = np.percentile(data, 40)\n",
        "seventy = np.percentile(data, 70)\n",
        "\n",
        "def get_quartiles(arr):\n",
        "  return twenty, forty, seventy\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Median: {median}\")\n",
        "print(f\"Mode: {mode_val}\")\n",
        "print(f\"Standard Deviation: {std_dev}\")\n",
        "print(f\"Minimum Value: {min_val}\")\n",
        "print(f\"Maximum Value: {max_val}\")\n",
        "print(f\" twenty: {twenty}\")\n",
        "print(f\"forty {forty}\")\n",
        "print(f\"seventy {seventy}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "s728escDFB6v"
      },
      "id": "s728escDFB6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def count_complexity_occurrences(file_path):\n",
        "    complexity_counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            data = json.loads(line)\n",
        "            complexity = data.get('completion')\n",
        "            # Check if 'complexity' exists and is in the range 1-5\n",
        "            if complexity is not None and int(complexity) in range(1, 6):\n",
        "                complexity_counts[int(complexity)] += 1\n",
        "\n",
        "    return complexity_counts\n",
        "\n",
        "# Replace 'file_path.jsonl' with the path to your JSONL file\n",
        "result = count_complexity_occurrences('mbpp_test_5class_completion.jsonl')\n",
        "\n",
        "print(\"Complexity Counts:\")\n",
        "for complexity, count in result.items():\n",
        "    print(f\"Complexity {complexity}: {count} occurrences\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q322nA-pyHA7",
        "outputId": "39bdb4e7-990c-443a-8a3d-d07452fa7c9c"
      },
      "id": "q322nA-pyHA7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complexity Counts:\n",
            "Complexity 1: 53 occurrences\n",
            "Complexity 2: 45 occurrences\n",
            "Complexity 3: 30 occurrences\n",
            "Complexity 4: 20 occurrences\n",
            "Complexity 5: 26 occurrences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def restrict_complexity(file_path):\n",
        "    restricted_data = []\n",
        "    complexity_counts = {1: 0, 2: 0}\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            data = json.loads(line)\n",
        "            complexity = data.get('completion')\n",
        "\n",
        "            if int(complexity) in (1, 2):\n",
        "                if complexity_counts[int(complexity)] < 30:\n",
        "                    restricted_data.append(data)\n",
        "                    complexity_counts[int(complexity)] += 1\n",
        "            else:\n",
        "                restricted_data.append(data)\n",
        "\n",
        "    # Write the modified data to a new file\n",
        "    with open('restricted_file.jsonl', 'w') as output_file:\n",
        "        for entry in restricted_data:\n",
        "            output_file.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "# Replace 'file_path.jsonl' with the path to your JSONL file\n",
        "restrict_complexity('mbpp_test_5class_completion.jsonl')\n"
      ],
      "metadata": {
        "id": "JM2XJECx0TuT"
      },
      "id": "JM2XJECx0TuT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "values = [18, 29]\n",
        "labels = ['Bar 1', 'Bar 2']\n",
        "highest_y = 34\n",
        "\n",
        "# Creating the bar chart\n",
        "plt.figure(figsize=(8, 6))  # Optional: Adjust figure size\n",
        "\n",
        "bars = plt.bar(labels, values, color=['blue', 'orange'])\n",
        "\n",
        "# Setting y-axis limit\n",
        "plt.ylim(0, highest_y)\n",
        "\n",
        "# Adding labels to bars\n",
        "for bar, label in zip(bars, labels):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, label,\n",
        "             ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Adding title and labels\n",
        "plt.title('Bar Chart with Labels')\n",
        "plt.xlabel('Bars')\n",
        "plt.ylabel('Values')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5JdN5SlB5Evv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "0a1d8030-4fb2-4e0d-85f4-8aec79f7824b"
      },
      "id": "5JdN5SlB5Evv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}