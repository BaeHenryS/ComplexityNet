pip install openai -q


from openai import OpenAI
client = OpenAI(api_key="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")


train_create = client.files.create(
  file=open("mbpp_chat_train.jsonl", "rb"),
  purpose="fine-tune"
)

val_create = client.files.create(
  file=open("mbpp_chat_test.jsonl", "rb"),
  purpose="fine-tune"
)


training_file = train_create.id
val_file = val_create.id
training_file, val_file


ft_create = client.fine_tuning.jobs.create(
  training_file=training_file, 
  model="gpt-3.5-turbo",
  # validation_file=val_file,
)


ft_create


ft_job = ft_create.id
ft_job


client.fine_tuning.jobs.retrieve(ft_job)


# ft_model = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model
# ft_model


ft_gpt3_5_800 = "ft:gpt-3.5-turbo-0613:personal::8OwzEA9b"


og_model = "gpt-3.5-turbo"


# ft_model = ft_gpt3_5_800


import json

input_file_path = "./mbpp_chat_test.jsonl"

with open(input_file_path, 'r') as file:
    # Extract the 'prompt' field from each JSON object in the file and collect them into a list
    messages = [json.loads(line)['messages'][:2] for line in file]

with open(input_file_path, 'r') as file:
    complexity = [json.loads(line)['messages'][2]["content"] for line in file]

complexity[:3]








messages[0]


res = client.chat.completions.create(
                  model=og_model,
                  messages=messages[0],
                  max_tokens=500)


res.choices[0].message.content


og_model_res = []
# ft_model_res = []
ft_model_res = []
# og_model_dav3_res = []

for message in messages:
    try: 
        og_response = client.chat.completions.create(
                      model=og_model,
                      messages=message,
                      max_tokens=1)
        og_model_res.append(og_response.choices[0].message.content)
    except:
        continue
    # ft_response = client.chat.completions.create(
    #               model=ft_model,
    #               messages=message,
    #               max_tokens=1)
    # ft_model_res.append(int(ft_response.choices[0].message.content))
    
    # ft_response2 = client.completions.create(
    #               model=ft_model2,
    #               prompt= prompt,
    #               max_tokens=1)
    # ft_model_res2.append(int(ft_response2.choices[0].text))
    # ft_response3 = client.completions.create(
    #               model=ft_model3,
    #               prompt= prompt,
    #               max_tokens=1)
    # ft_model_res3.append(int(ft_response3.choices[0].text))
    # og_dav3_response = client.completions.create(
    #               model=og_model_dav3,
    #               prompt= prompt,
    #               max_tokens=1)
    # og_model_dav3_res.append(int(og_dav3_response.choices[0].text))


len(complexity), len(og_model_res)


import pandas as pd


# Creating correctness columns
og_correctness = [l1 == int(gt) for l1, gt in zip(og_model_res, complexity[:173])]
ft_correctness = [l2 == int(gt) for l2, gt in zip(ft_model_res, complexity[:173])]
# ft_correctness2 = [l3 == int(gt) for l3, gt in zip(ft_model_res2, complexity)]
# ft_correctness3 = [l4 == int(gt) for l4, gt in zip(ft_model_res3, complexity)]

# Creating the DataFrame
df = pd.DataFrame({
    # 'prompt': prompts,
    'og': og_model_res,
    'og_correctness': og_correctness,
    'ft': ft_model_res,
    'ft_correctness': ft_correctness,
    # 'ft2': ft_model_res2,
    # 'ft_correctness2': ft_correctness2,
    # 'ft3': ft_model_res3,
    # 'ft_correctness3': ft_correctness3,
    'ground_truth': complexity[:173],
})

df


# ft_true_count2 = df['ft_correctness2'].sum()
og_true_count = df['og_correctness'].sum() 
ft_true_count = df['ft_correctness'].sum()
# ft_true_count3 = df['ft_correctness3'].sum()
ft_true_count, og_true_count


df.to_json("./test_results_chat_4classes.jsonl", orient='records', lines=True)


# ft_model_dav2_res = ft_model_res


# og_model_dav2_res = og_model_res



