{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ad434d-91f1-4a9c-925a-794b1c56b865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0087bb4-c674-475f-940e-c90ae3917809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edbbdaf7-7851-444c-8f79-bdcfa1a1a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_create = client.files.create(\n",
    "  file=open(\"mbpp_completion_3classes_train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "val_create = client.files.create(\n",
    "  file=open(\"mbpp_completion_3classes_test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acf5b22c-7aed-4787-bf3e-d4e27511cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('file-3urO0aqUHzOaCHLiFYahgQqS', 'file-uHPxirWDn9AMk66E3y64BYbF')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = train_create.id\n",
    "val_file = val_create.id\n",
    "training_file, val_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b40ebc87-b0b4-4f82-b155-9803ea3972de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "ft_create = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file, \n",
    "  model=\"text-davinci-003\",\n",
    "  validation_file=val_file,\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":4\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd069dc4-67fb-409e-99ff-479689b9326f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-xaYwQBLkP4CyJJKcEaOxWppI', created_at=1700949298, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=4, batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-C3Uef6f81pjJUiIQMtu8svVl', result_files=[], status='validating_files', trained_tokens=None, training_file='file-3urO0aqUHzOaCHLiFYahgQqS', validation_file='file-uHPxirWDn9AMk66E3y64BYbF')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "661d817e-195d-4a05-a8d7-8aa41f6daa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-xaYwQBLkP4CyJJKcEaOxWppI'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_job = ft_create.id\n",
    "ft_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14a3e11a-0210-46a0-bc5d-4ae20523a698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-xaYwQBLkP4CyJJKcEaOxWppI', created_at=1700949298, error=None, fine_tuned_model='ft:davinci-002:personal::8Ov33dCP', finished_at=1700949856, hyperparameters=Hyperparameters(n_epochs=4, batch_size=2, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-C3Uef6f81pjJUiIQMtu8svVl', result_files=['file-FQjZiHXe28sjTZ9R24AGaF6y'], status='succeeded', trained_tokens=237296, training_file='file-3urO0aqUHzOaCHLiFYahgQqS', validation_file='file-uHPxirWDn9AMk66E3y64BYbF')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(ft_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2aab4eb-e3bf-4bbd-9456-b20a9726ed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:davinci-002:personal::8Ov33dCP'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66843367-04d2-4fed-be68-a8c32311e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "  model=ft_model,\n",
    "  prompt= \"On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task 'Write a function to find whether all the given tuples have equal length or not.' is: \",\n",
    "  max_tokens=1\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad09c06a-98c8-4e08-9d56-6348a9610d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model = \"davinci-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f3c25d-7eea-4d6b-b88d-ffbf38714c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model_dav3 = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad9f194-e867-45a5-a01d-e366411d3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model2 = \"ft:davinci-002:personal::8OhPdNGc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3860c647-3dc9-451f-b9bb-556ffc48ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_full_4classes = \"ft:davinci-002:personal::8Otpm6EB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0c23c5-2eda-4076-b48c-dfcbb6a79860",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model3 = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7934a74-7108-4ddb-a212-e8d5d0a549f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_full_3classes = \"ft:davinci-002:personal::8Ov33dCP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f43a3b-88b1-4795-8724-9626ab584d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a function to find the maximum number of segments of lengths a, b and c that can be formed from n.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a function to concatenate the given two tuples to a nested tuple.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a python function to left rotate the string.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a function to find the minimum total path sum in the given triangle.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"None\" is: ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"./mbpp_completion_test.jsonl\"\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    # Extract the 'prompt' field from each JSON object in the file and collect them into a list\n",
    "    prompts = [json.loads(line)['prompt'] for line in file]\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    complexity = [json.loads(line)['completion'] for line in file]\n",
    "\n",
    "prompts[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60267d25-5fef-4208-ae3c-862427aa2e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# og_response = client.completions.create(\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#               model=og_model,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#               max_tokens=1)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# ft_model_res3.append(int(ft_response3.choices[0].text))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     og_dav3_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     29\u001b[0m                   model\u001b[38;5;241m=\u001b[39mog_model_dav3,\n\u001b[1;32m     30\u001b[0m                   prompt\u001b[38;5;241m=\u001b[39m prompt,\n\u001b[1;32m     31\u001b[0m                   max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m     og_model_dav3_res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mog_dav3_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '\\n'"
     ]
    }
   ],
   "source": [
    "# og_model_res = []\n",
    "# ft_model_res = []\n",
    "# ft_model_res = []\n",
    "og_model_dav3_res = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    # og_response = client.completions.create(\n",
    "    #               model=og_model,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # og_model_res.append(int(og_response.choices[0].text))\n",
    "    # ft_response = client.completions.create(\n",
    "    #               model=ft_model_full_3classes,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res.append(int(ft_response.choices[0].text))\n",
    "    \n",
    "    # ft_response2 = client.completions.create(\n",
    "    #               model=ft_model2,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res2.append(int(ft_response2.choices[0].text))\n",
    "    # ft_response3 = client.completions.create(\n",
    "    #               model=ft_model3,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res3.append(int(ft_response3.choices[0].text))\n",
    "    og_dav3_response = client.completions.create(\n",
    "                  model=og_model_dav3,\n",
    "                  prompt= prompt,\n",
    "                  max_tokens=1)\n",
    "    og_model_dav3_res.append(int(og_dav3_response.choices[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25835919-5859-458d-ac83-302168d8f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410cd9cc-f76d-4433-aa16-73966a1ecbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og</th>\n",
       "      <th>og_correctness</th>\n",
       "      <th>ft</th>\n",
       "      <th>ft_correctness</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     og  og_correctness  ft  ft_correctness ground_truth\n",
       "0     2           False   1           False            0\n",
       "1     2           False   0           False            1\n",
       "2     1           False   0            True            0\n",
       "3     1            True   2           False            1\n",
       "4     1           False   2           False            0\n",
       "..   ..             ...  ..             ...          ...\n",
       "169   1           False   2            True            2\n",
       "170   2           False   2           False            0\n",
       "171   2           False   1           False            0\n",
       "172   0           False   1            True            1\n",
       "173   1            True   0           False            1\n",
       "\n",
       "[174 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Creating correctness columns\n",
    "og_correctness = [l1 == int(gt) for l1, gt in zip(og_model_res, complexity)]\n",
    "ft_correctness = [l2 == int(gt) for l2, gt in zip(ft_model_res, complexity)]\n",
    "# ft_correctness2 = [l3 == int(gt) for l3, gt in zip(ft_model_res2, complexity)]\n",
    "# ft_correctness3 = [l4 == int(gt) for l4, gt in zip(ft_model_res3, complexity)]\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    # 'prompt': prompts,\n",
    "    'og': og_model_res,\n",
    "    'og_correctness': og_correctness,\n",
    "    'ft': ft_model_res,\n",
    "    'ft_correctness': ft_correctness,\n",
    "    # 'ft2': ft_model_res2,\n",
    "    # 'ft_correctness2': ft_correctness2,\n",
    "    # 'ft3': ft_model_res3,\n",
    "    # 'ft_correctness3': ft_correctness3,\n",
    "    'ground_truth': complexity,\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfec56df-1460-41dc-bdf4-7fbbc2aeab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f038fe78-4857-4ac8-8d5e-2be90b7bdc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 44)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ft_true_count2 = df['ft_correctness2'].sum()\n",
    "og_true_count = df['og_correctness'].sum() \n",
    "ft_true_count = df['ft_correctness'].sum()\n",
    "# ft_true_count3 = df['ft_correctness3'].sum()\n",
    "ft_true_count, og_true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e1e7c4-fd03-43a2-a2d7-84ef737094f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"./test_results_3classes.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ad9749-2851-4383-acc3-7a4f9368c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model_dav2_res = ft_model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07e28a7-9994-47ea-82f0-de5b1e0ede2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# og_model_dav2_res = og_model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea84f5-561c-46bd-a785-4bbefc61f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
