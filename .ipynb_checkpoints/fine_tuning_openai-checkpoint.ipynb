{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ad434d-91f1-4a9c-925a-794b1c56b865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edbbdaf7-7851-444c-8f79-bdcfa1a1a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "train_create = client.files.create(\n",
    "  file=open(\"mbpp_completion_3classes_train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "val_create = client.files.create(\n",
    "  file=open(\"mbpp_completion_3classes_test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acf5b22c-7aed-4787-bf3e-d4e27511cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('file-3urO0aqUHzOaCHLiFYahgQqS', 'file-uHPxirWDn9AMk66E3y64BYbF')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = train_create.id\n",
    "val_file = val_create.id\n",
    "training_file, val_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b40ebc87-b0b4-4f82-b155-9803ea3972de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "ft_create = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file, \n",
    "  model=\"davinci-002\",\n",
    "  validation_file=val_file,\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":4\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd069dc4-67fb-409e-99ff-479689b9326f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-xaYwQBLkP4CyJJKcEaOxWppI', created_at=1700949298, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=4, batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-C3Uef6f81pjJUiIQMtu8svVl', result_files=[], status='validating_files', trained_tokens=None, training_file='file-3urO0aqUHzOaCHLiFYahgQqS', validation_file='file-uHPxirWDn9AMk66E3y64BYbF')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "661d817e-195d-4a05-a8d7-8aa41f6daa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-xaYwQBLkP4CyJJKcEaOxWppI'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_job = ft_create.id\n",
    "ft_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14a3e11a-0210-46a0-bc5d-4ae20523a698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-xaYwQBLkP4CyJJKcEaOxWppI', created_at=1700949298, error=None, fine_tuned_model='ft:davinci-002:personal::8Ov33dCP', finished_at=1700949856, hyperparameters=Hyperparameters(n_epochs=4, batch_size=2, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-C3Uef6f81pjJUiIQMtu8svVl', result_files=['file-FQjZiHXe28sjTZ9R24AGaF6y'], status='succeeded', trained_tokens=237296, training_file='file-3urO0aqUHzOaCHLiFYahgQqS', validation_file='file-uHPxirWDn9AMk66E3y64BYbF')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(ft_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2aab4eb-e3bf-4bbd-9456-b20a9726ed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:davinci-002:personal::8Ov33dCP'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66843367-04d2-4fed-be68-a8c32311e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "  model=ft_model,\n",
    "  prompt= \"On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task 'Write a function to find whether all the given tuples have equal length or not.' is: \",\n",
    "  max_tokens=1\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad09c06a-98c8-4e08-9d56-6348a9610d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model = \"davinci-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad9f194-e867-45a5-a01d-e366411d3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model2 = \"ft:davinci-002:personal::8OhPdNGc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3860c647-3dc9-451f-b9bb-556ffc48ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_full_4classes = \"ft:davinci-002:personal::8Otpm6EB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0c23c5-2eda-4076-b48c-dfcbb6a79860",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model3 = client.fine_tuning.jobs.retrieve(ft_job).fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7934a74-7108-4ddb-a212-e8d5d0a549f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_full_3classes = \"ft:davinci-002:personal::8Ov33dCP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f43a3b-88b1-4795-8724-9626ab584d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a function to find the maximum number of segments of lengths a, b and c that can be formed from n.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a function to concatenate the given two tuples to a nested tuple.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a python function to left rotate the string.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"Write a function to find the minimum total path sum in the given triangle.\" is: ',\n",
       " 'On a scale of 0 to 2 based solely on the complexity of creating the correct code for the task, where 0 represents a simpler task, 1 represents a moderately challenging task, and 2 represents a highly complex problem, the complexity of the task \"None\" is: ']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"./mbpp_completion_test.jsonl\"\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    # Extract the 'prompt' field from each JSON object in the file and collect them into a list\n",
    "    prompts = [json.loads(line)['prompt'] for line in file]\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    complexity = [json.loads(line)['completion'] for line in file]\n",
    "\n",
    "prompts[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60267d25-5fef-4208-ae3c-862427aa2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model_res = []\n",
    "# ft_model_res = []\n",
    "ft_model_res = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    og_response = client.completions.create(\n",
    "                  model=og_model,\n",
    "                  prompt= prompt,\n",
    "                  max_tokens=1)\n",
    "    og_model_res.append(int(og_response.choices[0].text))\n",
    "    ft_response = client.completions.create(\n",
    "                  model=ft_model,\n",
    "                  prompt= prompt,\n",
    "                  max_tokens=1)\n",
    "    ft_model_res.append(int(ft_response.choices[0].text))\n",
    "    # ft_response2 = client.completions.create(\n",
    "    #               model=ft_model2,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res2.append(int(ft_response2.choices[0].text))\n",
    "    # ft_response3 = client.completions.create(\n",
    "    #               model=ft_model3,\n",
    "    #               prompt= prompt,\n",
    "    #               max_tokens=1)\n",
    "    # ft_model_res3.append(int(ft_response3.choices[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25835919-5859-458d-ac83-302168d8f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cd9cc-f76d-4433-aa16-73966a1ecbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Creating correctness columns\n",
    "og_correctness = [l1 == int(gt) for l1, gt in zip(og_model_res, complexity)]\n",
    "ft_correctness = [l2 == int(gt) for l2, gt in zip(ft_model_res, complexity)]\n",
    "# ft_correctness2 = [l3 == int(gt) for l3, gt in zip(ft_model_res2, complexity)]\n",
    "# ft_correctness3 = [l4 == int(gt) for l4, gt in zip(ft_model_res3, complexity)]\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    # 'prompt': prompts,\n",
    "    'og': og_model_res,\n",
    "    'og_correctness': og_correctness,\n",
    "    'ft': ft_model_res,\n",
    "    'ft_correctness': ft_correctness,\n",
    "    # 'ft2': ft_model_res2,\n",
    "    # 'ft_correctness2': ft_correctness2,\n",
    "    # 'ft3': ft_model_res3,\n",
    "    # 'ft_correctness3': ft_correctness3,\n",
    "    'ground_truth': complexity,\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec56df-1460-41dc-bdf4-7fbbc2aeab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f038fe78-4857-4ac8-8d5e-2be90b7bdc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ft_true_count2 = df['ft_correctness2'].sum()\n",
    "og_true_count = df['og_correctness'].sum() \n",
    "ft_true_count = df['ft_correctness'].sum()\n",
    "# ft_true_count3 = df['ft_correctness3'].sum()\n",
    "ft_true_count, og_true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0e1e7c4-fd03-43a2-a2d7-84ef737094f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"./test_results_4classes.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad9749-2851-4383-acc3-7a4f9368c57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
