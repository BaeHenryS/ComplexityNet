{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YyVCL6Ksj50"
      },
      "source": [
        "Below we use 7b param code llama 2 specialized for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TLnE72tsd1u"
      },
      "outputs": [],
      "source": [
        "# import sentencepiece\n",
        "# from transformers import LlamaForCausalLM, CodeLlamaTokenizer\n",
        "\n",
        "# tokenizer = CodeLlamaTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")\n",
        "# model = LlamaForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRjKJVBIspPr"
      },
      "outputs": [],
      "source": [
        "# PROMPT = '''Write a function to find the length of the shortest string that has both str1 and str2 as subsequences.\n",
        "# def super_seq(X, Y, m, n):\n",
        "# <FILL_ME>\n",
        "# return result\n",
        "# '''\n",
        "# input_ids = tokenizer(PROMPT, return_tensors=\"pt\")[\"input_ids\"]\n",
        "# generated_ids = model.generate(input_ids, max_new_tokens=128)\n",
        "\n",
        "# filling = tokenizer.batch_decode(generated_ids[:, input_ids.shape[1]:], skip_special_tokens = True)[0]\n",
        "# print(PROMPT.replace(\"<FILL_ME>\", filling))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mT_a-HW75t0"
      },
      "outputs": [],
      "source": [
        "def find_def_until_colon(input_string):\n",
        "    def_index = input_string.find('def')\n",
        "\n",
        "    if def_index != -1:\n",
        "        colon_index = input_string.find(':', def_index)\n",
        "\n",
        "        if colon_index != -1:\n",
        "            return input_string[def_index:colon_index + 1]\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWvcTeKT_BcI"
      },
      "outputs": [],
      "source": [
        "def everything_after_def(input_string):\n",
        "    def_index = input_string.find('def')\n",
        "\n",
        "    if def_index != -1:\n",
        "        double_newline_index = input_string.find('\\n\\n', def_index)\n",
        "        if double_newline_index != -1:\n",
        "            result = input_string[def_index:double_newline_index]\n",
        "            return result\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def everything_after_def_2(input_string):\n",
        "    def_index = input_string.find('def')\n",
        "\n",
        "    if def_index != -1:\n",
        "        substring_from_def = input_string[def_index:]\n",
        "\n",
        "        return_index = substring_from_def.rfind('return')\n",
        "        if return_index != -1:\n",
        "            newline_index = substring_from_def.find('\\n', return_index)\n",
        "            if newline_index != -1:\n",
        "                result = substring_from_def[:newline_index]\n",
        "                return result.strip()\n",
        "            else:\n",
        "                result = substring_from_def[:return_index]\n",
        "                return result.strip()\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "uzloRn0uSTEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = \"\\ndef is_Monotonic(A):\\r\\n    return all(A[i] <= A[i + 1] for i in range(len(A) - 1)) or all(A[i] >= A[i + 1] for i in range(len(A) - 1))\\r\\n\""
      ],
      "metadata": {
        "id": "qK5tq177KsOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(everything_after_def_2(testing) == everything_after_def(testing))\n",
        "everything_after_def_2(testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kKPOPrEwLCJY",
        "outputId": "ee56c488-5b14-4afc-aaf6-566a8477dd58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def is_Monotonic(A):\\r\\n    return all(A[i] <= A[i + 1] for i in range(len(A) - 1)) or all(A[i] >= A[i + 1] for i in range(len(A) - 1))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIzwEW4-B1EL"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# def extract_args_with_function_name(declaration):\n",
        "#     pattern = r'def\\s+(\\w+)\\s*\\((.*?)\\)'\n",
        "\n",
        "#     match = re.search(pattern, declaration)\n",
        "\n",
        "#     if match:\n",
        "#         function_name = match.group(1)\n",
        "#         arguments = match.group(2).split(', ')\n",
        "#     else:\n",
        "#         function_name = \"\"\n",
        "#         arguments = []\n",
        "\n",
        "#     if len(arguments) == 0:\n",
        "#         return function_name, \"that takes no arguments\"\n",
        "#     elif len(arguments) == 1:\n",
        "#         return function_name, f\"that takes {arguments[0]} as an argument\"\n",
        "#     else:\n",
        "#         args_except_last = \", \".join(arguments[:-1])\n",
        "#         last_arg = arguments[-1]\n",
        "#         return function_name, f\"that takes {args_except_last} and {last_arg} as arguments\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YHubY-c_7iw"
      },
      "outputs": [],
      "source": [
        "def proper_format(prompt_in, code_in):\n",
        "    # str_1 = \" \"\n",
        "    # fun_name, str_2 = extract_args_with_function_name(code_in)\n",
        "    function_index = prompt_in.find(\"to\")\n",
        "    if function_index != -1:\n",
        "        result = prompt_in[function_index + len(\"to\"):].strip()\n",
        "        return result + \" \\n\" + find_def_until_colon(code_in)\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjG7Ctfx48Ir"
      },
      "outputs": [],
      "source": [
        "# def getCodeFormat(prompt_in, code_in):\n",
        "#     prompt = proper_format(prompt_in, code_in)\n",
        "\n",
        "#     input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
        "#     attention_mask = torch.ones_like(input_ids)\n",
        "#     pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "#     generated_ids = model.generate(\n",
        "#         input_ids,\n",
        "#         attention_mask=attention_mask,\n",
        "#         pad_token_id=pad_token_id,\n",
        "#         max_new_tokens=128,\n",
        "#         num_return_sequences=1\n",
        "#     )\n",
        "\n",
        "#     generated_code = tokenizer.batch_decode(\n",
        "#         generated_ids[:, input_ids.shape[1]:],\n",
        "#         skip_special_tokens=True\n",
        "#     )[0]\n",
        "\n",
        "#     # Assuming generated_code directly contains the code without placeholders\n",
        "#     return generated_code\n",
        "\n",
        "\n",
        "# print(getCodeFormat(\"Write a python function to find the length of the shortest word.\", \"def len_log(list1): min=len(list1[0]) for i in list1: if len(i)<min: min=len(i) return min\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJYhTBXfKJke"
      },
      "outputs": [],
      "source": [
        "# def getCodeFormat(prompt_in, code_in):\n",
        "#     PROMPT = proper_format(prompt_in, code_in)\n",
        "#     input_ids = tokenizer(PROMPT, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "#     attention_mask = torch.ones_like(input_ids)  # Set attention mask to ones (all tokens are attended to)\n",
        "#     pad_token_id = tokenizer.eos_token_id  # Get the pad token ID\n",
        "\n",
        "#     generated_ids = model.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id, max_new_tokens=128, num_return_sequences=1)\n",
        "#     filling = tokenizer.batch_decode(generated_ids[:, input_ids.shape[1]:], skip_special_tokens = True)[0]\n",
        "#     print(\"hello\" + filling)\n",
        "#     responseText = PROMPT.replace(\"<FILL_ME>\", filling)\n",
        "\n",
        "#     return filling\n",
        "\n",
        "# print(getCodeFormat(\"Write a python function to find the length of the shortest word.\", \"def len_log(list1): min=len(list1[0]) for i in list1: if len(i)<min: min=len(i) return min\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/huggingface/transformers.git@main accelerate"
      ],
      "metadata": {
        "id": "o4DNSMPw1y90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"codellama/CodeLlama-7b-Python-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "9CEtY1rU2ceE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateCode(prompt_input, code_input):\n",
        "  sequences = pipeline(\n",
        "      proper_format(prompt_input, code_input),\n",
        "      do_sample=True,\n",
        "      top_k=10,\n",
        "      temperature=1,\n",
        "      top_p=0.95,\n",
        "      num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      max_length=200,\n",
        "  )\n",
        "  return everything_after_def_2(sequences[0]['generated_text'])\n",
        "\n",
        "# print(getCodeFormat(\"Write a python function to find the length of the shortest word.\", \"def len_log(list1): min=len(list1[0]) for i in list1: if len(i)<min: min=len(i) return min\"))"
      ],
      "metadata": {
        "id": "e52vJK_P3nH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'"
      ],
      "metadata": {
        "id": "4dz-ViOC-Ueh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flwk_xIe9Wxi"
      },
      "outputs": [],
      "source": [
        "# import jsonlines\n",
        "# import torch\n",
        "\n",
        "\n",
        "# max_loop = 20\n",
        "# i = 0\n",
        "\n",
        "# with jsonlines.open('mbpp.jsonl') as reader:\n",
        "# # Loop through each example\n",
        "#     for obj in reader:\n",
        "#         prompt = obj['text']\n",
        "#         code = obj['code']\n",
        "\n",
        "#         print(find_def_until_colon(code))\n",
        "\n",
        "#         responseText = getCodeFormat(prompt, code)\n",
        "\n",
        "#         print(responseText)\n",
        "\n",
        "#         try:\n",
        "#           exec(responseText)\n",
        "#         except Exception as E:\n",
        "#           print(\"Code Didn't Run\")\n",
        "#           print(\"Error\" + str(E))\n",
        "#           continue\n",
        "\n",
        "#         # Assertion Code:\n",
        "#         assertion_code = obj['test_list']\n",
        "#         # Execute and print if the code passes the assertions\n",
        "#         for assertion in assertion_code:\n",
        "#             print(assertion)\n",
        "#             try:\n",
        "#                 exec(assertion)\n",
        "#             except Exception as E:\n",
        "#                 # Continue to the next example and print the error\n",
        "#                 print(\"Code Failed Assertions\" + str(E))\n",
        "#                 break\n",
        "\n",
        "#         # terminate loop for testing\n",
        "#         i += 1\n",
        "#         if i == max_loop:\n",
        "#             break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jsonlines"
      ],
      "metadata": {
        "id": "u1Fkj-mkZ0Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "5mJmXbKyZ84X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import jsonlines\n",
        "import os\n",
        "# import openai\n",
        "# from openai import OpenAI\n",
        "# from dotenv import load_dotenv\n",
        "import textwrap\n",
        "import signal\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "\n",
        "class TimeoutException(Exception): pass\n",
        "\n",
        "@contextmanager\n",
        "def time_limit(seconds):\n",
        "    def signal_handler(signum, frame):\n",
        "        raise TimeoutException(\"Timed out!\")\n",
        "    signal.signal(signal.SIGALRM, signal_handler)\n",
        "    signal.alarm(seconds)\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        signal.alarm(0)\n",
        "\n",
        "\n",
        "import bisect\n",
        "import collections\n",
        "import math\n",
        "import heapq\n",
        "import operator\n",
        "import datetime\n",
        "import itertools\n",
        "import cmath\n",
        "import sys\n",
        "import re\n",
        "import array\n",
        "import copy\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "\n",
        "def checkCorrectness(output, obj):\n",
        "    try:\n",
        "      exec(output)\n",
        "    except:\n",
        "      print(\"Code didnt compile\")\n",
        "      success = False\n",
        "      return False\n",
        "\n",
        "    assertion_code = obj['test_list']\n",
        "\n",
        "    success = True\n",
        "    for assertion in assertion_code:\n",
        "        try:\n",
        "            exec(assertion)\n",
        "            print(\"Code Passed Assertions\")\n",
        "        except Exception as e:\n",
        "            # Continue to the next example and print the error\n",
        "            print(f\"Error: {e}\")\n",
        "            print(\"Code Failed Assertions\")\n",
        "            success = False\n",
        "    return success\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # #max_loop = 974\n",
        "    max_loop = 300\n",
        "    start_line = 151  # Start processing from the 43rd line\n",
        "    with jsonlines.open('mbpp_label_refined.jsonl') as reader:\n",
        "        i = sum(1 for _ in reader)\n",
        "\n",
        "    with jsonlines.open('mbpp.jsonl') as reader:\n",
        "        # Loop through each example\n",
        "        for count, obj in enumerate(reader):\n",
        "            # Start from the last example that was run\n",
        "            with jsonlines.open('mbpp_label_refined.jsonl') as reader:\n",
        "                i = sum(1 for _ in reader)\n",
        "            if count < start_line - 1 or count < i:\n",
        "                continue\n",
        "\n",
        "            code_llama_2 = 0\n",
        "            success_gpt4 = 0\n",
        "\n",
        "            for _ in range(5):\n",
        "                print(\"Running Code Llama 2\")\n",
        "                code_llama_response = generateCode(obj['text'], obj['code'])\n",
        "                print(code_llama_response)\n",
        "                if checkCorrectness(code_llama_response, obj):\n",
        "                    code_llama_2 += 1\n",
        "\n",
        "                time.sleep(5)\n",
        "\n",
        "            obj[\"code_llama_response\"] = code_llama_response\n",
        "            obj[\"code_llama_success\"] = code_llama_2\n",
        "\n",
        "            with jsonlines.open('mbpp_label_refined.jsonl', mode='a') as writer:\n",
        "                writer.write(obj)\n",
        "\n",
        "            if i == max_loop:\n",
        "                break\n",
        "\n",
        "\n",
        "            time.sleep(5)"
      ],
      "metadata": {
        "id": "2c7KHErQDJgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}