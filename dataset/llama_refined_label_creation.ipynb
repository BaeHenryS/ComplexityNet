{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YyVCL6Ksj50"
      },
      "source": [
        "Below we use 7b param code llama 2 specialized for Python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are 3 helper functions to get the input into the model in the optimal format - arrived at through prompt engineering"
      ],
      "metadata": {
        "id": "DwG3eNXPDFBd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mT_a-HW75t0"
      },
      "outputs": [],
      "source": [
        "def find_def_until_colon(input_string):\n",
        "    def_index = input_string.find('def')\n",
        "\n",
        "    if def_index != -1:\n",
        "        colon_index = input_string.find(':', def_index)\n",
        "\n",
        "        if colon_index != -1:\n",
        "            return input_string[def_index:colon_index + 1]\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def everything_after_def_2(input_string):\n",
        "    def_index = input_string.find('def')\n",
        "\n",
        "    if def_index != -1:\n",
        "        substring_from_def = input_string[def_index:]\n",
        "\n",
        "        return_index = substring_from_def.rfind('return')\n",
        "        if return_index != -1:\n",
        "            newline_index = substring_from_def.find('\\n', return_index)\n",
        "            if newline_index != -1:\n",
        "                result = substring_from_def[:newline_index]\n",
        "                return result.strip()\n",
        "            else:\n",
        "                result = substring_from_def[:return_index]\n",
        "                return result.strip()\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "uzloRn0uSTEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YHubY-c_7iw"
      },
      "outputs": [],
      "source": [
        "def proper_format(prompt_in, code_in):\n",
        "    # str_1 = \" \"\n",
        "    # fun_name, str_2 = extract_args_with_function_name(code_in)\n",
        "    function_index = prompt_in.find(\"to\")\n",
        "    if function_index != -1:\n",
        "        result = prompt_in[function_index + len(\"to\"):].strip()\n",
        "        return result + \" \\n\" + find_def_until_colon(code_in)\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we use HuggingFace"
      ],
      "metadata": {
        "id": "AvPjcL4TDL4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/huggingface/transformers.git@main accelerate"
      ],
      "metadata": {
        "id": "o4DNSMPw1y90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"codellama/CodeLlama-7b-Python-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "9CEtY1rU2ceE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateCode(prompt_input, code_input):\n",
        "  sequences = pipeline(\n",
        "      proper_format(prompt_input, code_input),\n",
        "      do_sample=True,\n",
        "      top_k=10,\n",
        "      temperature=1,\n",
        "      top_p=0.95,\n",
        "      num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      max_length=200,\n",
        "  )\n",
        "  return everything_after_def_2(sequences[0]['generated_text'])\n",
        "\n",
        "# print(getCodeFormat(\"Write a python function to find the length of the shortest word.\", \"def len_log(list1): min=len(list1[0]) for i in list1: if len(i)<min: min=len(i) return min\"))"
      ],
      "metadata": {
        "id": "e52vJK_P3nH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'"
      ],
      "metadata": {
        "id": "4dz-ViOC-Ueh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jsonlines"
      ],
      "metadata": {
        "id": "u1Fkj-mkZ0Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the API calls and append the results to the output file"
      ],
      "metadata": {
        "id": "tC64oIrEDQ77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import jsonlines\n",
        "import os\n",
        "import textwrap\n",
        "import signal\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "\n",
        "class TimeoutException(Exception): pass\n",
        "\n",
        "@contextmanager\n",
        "def time_limit(seconds):\n",
        "    def signal_handler(signum, frame):\n",
        "        raise TimeoutException(\"Timed out!\")\n",
        "    signal.signal(signal.SIGALRM, signal_handler)\n",
        "    signal.alarm(seconds)\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        signal.alarm(0)\n",
        "\n",
        "\n",
        "import bisect\n",
        "import collections\n",
        "import math\n",
        "import heapq\n",
        "import operator\n",
        "import datetime\n",
        "import itertools\n",
        "import cmath\n",
        "import sys\n",
        "import re\n",
        "import array\n",
        "import copy\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "\n",
        "def checkCorrectness(output, obj):\n",
        "    try:\n",
        "      exec(output)\n",
        "    except:\n",
        "      print(\"Code didnt compile\")\n",
        "      success = False\n",
        "      return False\n",
        "\n",
        "    assertion_code = obj['test_list']\n",
        "\n",
        "    success = True\n",
        "    for assertion in assertion_code:\n",
        "        try:\n",
        "            exec(assertion)\n",
        "            print(\"Code Passed Assertions\")\n",
        "        except Exception as e:\n",
        "            # Continue to the next example and print the error\n",
        "            print(f\"Error: {e}\")\n",
        "            print(\"Code Failed Assertions\")\n",
        "            success = False\n",
        "    return success\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # #max_loop = 974\n",
        "    max_loop = 300\n",
        "\n",
        "    #run 150 next\n",
        "    start_line = 150\n",
        "    with jsonlines.open('mbpp_label_refined.jsonl') as reader:\n",
        "        i = sum(1 for _ in reader)\n",
        "\n",
        "    with jsonlines.open('mbpp.jsonl') as reader:\n",
        "        # Loop through each example\n",
        "        for count, obj in enumerate(reader):\n",
        "            # Start from the last example that was run\n",
        "            with jsonlines.open('mbpp_label_refined.jsonl') as reader:\n",
        "                i = sum(1 for _ in reader)\n",
        "            if count < start_line - 1:\n",
        "                continue\n",
        "\n",
        "            code_llama_2 = 0\n",
        "            success_gpt4 = 0\n",
        "            print(obj['text'])\n",
        "            for _ in range(5):\n",
        "                print(\"Running Code Llama 2\")\n",
        "                code_llama_response = generateCode(obj['text'], obj['code'])\n",
        "                print(code_llama_response)\n",
        "                if checkCorrectness(code_llama_response, obj):\n",
        "                    code_llama_2 += 1\n",
        "\n",
        "                time.sleep(5)\n",
        "\n",
        "            obj[\"code_llama_response\"] = code_llama_response\n",
        "            obj[\"code_llama_success\"] = code_llama_2\n",
        "\n",
        "            with jsonlines.open('mbpp_label_refined.jsonl', mode='a') as writer:\n",
        "                writer.write(obj)\n",
        "\n",
        "            if i == max_loop:\n",
        "                break\n",
        "\n",
        "\n",
        "            time.sleep(5)"
      ],
      "metadata": {
        "id": "2c7KHErQDJgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}