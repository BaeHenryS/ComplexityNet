{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/69/95/22a9a81cebd54e18841da429f05f06ed867648768f7af938ad34f13197fd/openai-1.3.3-py3-none-any.whl.metadata\n",
      "  Using cached openai-1.3.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/e2/2c/9906b7abc337b0250a5634de5396e2f3cb1b837af0616424c2225a65aa80/pydantic-2.5.1-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.5.1-py3-none-any.whl.metadata (64 kB)\n",
      "Requirement already satisfied: tqdm>4 in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.2)\n",
      "Requirement already satisfied: certifi in /Users/henrybae/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.3 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for pydantic-core==2.14.3 from https://files.pythonhosted.org/packages/ce/66/1686ffe300019238208fc38bc9f90678e85fae1e07de94ac0bd2736d11b6/pydantic_core-2.14.3-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached pydantic_core-2.14.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions<5,>=4.5 (from openai)\n",
      "  Obtaining dependency information for typing-extensions<5,>=4.5 from https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached openai-1.3.3-py3-none-any.whl (220 kB)\n",
      "Using cached httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "Using cached pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
      "Using cached pydantic_core-2.14.3-cp310-cp310-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: typing-extensions, h11, distro, annotated-types, pydantic-core, httpcore, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-macos 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.6.0 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.3 pydantic-2.5.1 pydantic-core-2.14.3 typing-extensions-4.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "# Check to see if there is an environment variable with you API keys, if not, use what you put below\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get('OPENAI_API_KEY',\"\"), \n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will generate a Python Script that will complete the task outlined by the user. You will not provide any explanations, and only return the Python Script without the explanation of the code. \"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\\t\\nWrite a function to find the longest chain which can be formed from the given set of pairs. The name of the function should be \\n\\nClass Pair(object)\\n\\ndef max_chain_length(arr, n)\\n\\n\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=2047,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "class Pair(object):\n",
      "    def __init__(self, a, b):\n",
      "        self.a = a\n",
      "        self.b = b\n",
      "\n",
      "def max_chain_length(arr, n):\n",
      "    arr.sort(key = lambda x: x.b)\n",
      "\n",
      "    max_length = 1\n",
      "    prev = arr[0]\n",
      "    for i in range(1, n):\n",
      "        if arr[i].a > prev.b:\n",
      "            max_length += 1\n",
      "            prev = arr[i]\n",
      "            \n",
      "    return max_length\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Passed Assertions\n"
     ]
    }
   ],
   "source": [
    "responseText = response.choices[0].message.content\n",
    "\n",
    "# Remove the ```python and ``` from the response\n",
    "responseText = responseText.replace(\"```python\", \"\")\n",
    "responseText = responseText.replace(\"```\", \"\")\n",
    "\n",
    "# Run the code\n",
    "exec(responseText)\n",
    "\n",
    "# Assertion Code:\n",
    "\n",
    "assertion_code = [ \"assert max_chain_length([Pair(5, 24), Pair(15, 25),Pair(27, 40), Pair(50, 60)], 4) == 3\", \"assert max_chain_length([Pair(1, 2), Pair(3, 4),Pair(5, 6), Pair(7, 8)], 4) == 4\", \"assert max_chain_length([Pair(19, 10), Pair(11, 12),Pair(13, 14), Pair(15, 16), Pair(31, 54)], 5) == 5\" ]\n",
    "\n",
    "# Execute and print if the code passes the assertions\n",
    "\n",
    "for assertion in assertion_code:\n",
    "    exec(assertion)\n",
    "\n",
    "print(\"Code Passed Assertions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCodeFormat(code_input):\n",
    "    # Make an OPENAI API Call to only return the function call and its inputs\n",
    "    '''EXAMPLE:\n",
    "    INPUT: class Pair(object): def __init__(self, a, b): self.a = a self.b = b def max_chain_length(arr, n): max = 0 mcl = [1 for i in range(n)] for i in range(1, n): for j in range(0, i): if (arr[i].a > arr[j].b and mcl[i] < mcl[j] + 1): mcl[i] = mcl[j] + 1 for i in range(n): if (max < mcl[i]): max = mcl[i] return max\n",
    "    \n",
    "    OUTPUT: Class Pair(object) def max_chain_length(arr, n)\n",
    "    '''\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ.get('OPENAI_API_KEY',\"\")\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Return only the function definition and its inputs from the code given by the user. Example: INPUT: class Pair(object): def __init__(self, a, b): self.a = a self.b = b def max_chain_length(arr, n): max = 0 mcl = [1 for i in range(n)] for i in range(1, n): for j in range(0, i): if (arr[i].a > arr[j].b and mcl[i] < mcl[j] + 1): mcl[i] = mcl[j] + 1 for i in range(n): if (max < mcl[i]): max = mcl[i] return max OUTPUT: Class Pair(object) def max_chain_length(arr, n) \"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": code_input\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    responseText = response.choices[0].message.content\n",
    "\n",
    "    # Remove the ```python and ``` from the response\n",
    "    responseText = responseText.replace(\"```python\", \"\")\n",
    "    responseText = responseText.replace(\"```\", \"\")\n",
    "\n",
    "    return responseText\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Example: 0\n",
      "def count_common(words)\n",
      "Code Failed Assertions\n",
      "Running Example: 1\n",
      "def find_Volume(l, b, h)\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Running Example: 2\n",
      "def split_lowerstring(text)\n",
      "Code Failed Assertions\n",
      "Running Example: 3\n",
      "def text_lowercase_underscore(text)\n",
      "Code Failed Assertions\n",
      "Running Example: 4\n",
      "\n",
      "def square_perimeter(a)\n",
      "\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Running Example: 5\n",
      "def str_to_list(string): \n",
      "def lst_to_string(List): \n",
      "def get_char_count_array(string): \n",
      "def remove_dirty_chars(string, second_string): \n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Running Example: 6\n",
      "def test_duplicate(arraynums)\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Running Example: 7\n",
      "def is_woodall(x)\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Running Example: 8\n",
      "def multiples_of_num(m, n)\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Running Example: 9\n",
      "def find_first_duplicate(nums)\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n",
      "Code Passed Assertions\n"
     ]
    }
   ],
   "source": [
    "# The entire loop now for each examples\n",
    "\n",
    "import jsonlines\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY',\"\")\n",
    "\n",
    "max_loop = 10\n",
    "i = 0\n",
    "\n",
    "success = 0\n",
    "\n",
    "# Open JSONL File:\n",
    "with jsonlines.open('mbpp.jsonl') as reader: \n",
    "# Loop through each example\n",
    "    for obj in reader:\n",
    "        print(\"Running Example: \" + str(i))\n",
    "        prompt = obj['text']\n",
    "        code = obj['code']\n",
    "        #print(obj['code'])\n",
    "        # Call the getCodeFormat function to get the function call and its inputs\n",
    "        function_call = getCodeFormat(code)\n",
    "        print(function_call)\n",
    "        userPrompt =  prompt + \" The name of the function should be \"  + function_call + \"\\n\\n\"\n",
    "        client = OpenAI(\n",
    "  api_key=os.environ.get('OPENAI_API_KEY',\"\"), \n",
    ")\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will generate a Python Script that will complete the task outlined by the user. You will not provide any explanations, and only return the Python Script without the explanation of the code. \"\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": userPrompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=2047,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "\n",
    "        responseText = response.choices[0].message.content\n",
    "\n",
    "        # Remove the ```python and ``` from the response\n",
    "        responseText = responseText.replace(\"```python\", \"\")\n",
    "        responseText = responseText.replace(\"```\", \"\")\n",
    "        \n",
    "        # Run the code\n",
    "        exec(responseText)\n",
    "\n",
    "        # Assertion Code:\n",
    "        assertion_code = obj['test_list']\n",
    "        # Execute and print if the code passes the assertions\n",
    "        for assertion in assertion_code:\n",
    "\n",
    "            try:\n",
    "                exec(assertion)\n",
    "                print(\"Code Passed Assertions\")\n",
    "                success += 1\n",
    "            except:\n",
    "                # Continue to the next example and print the error\n",
    "                print(\"Code Failed Assertions\")\n",
    "                break\n",
    "\n",
    "        import time \n",
    "        time.sleep(5)\n",
    "        \n",
    "        # terminate loop for testing\n",
    "        i += 1\n",
    "        if i == max_loop:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 16 out of 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Success: \" + str(success) + \" out of \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 21 out of 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Success: \" + str(success) + \" out of \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Examples: 974\n"
     ]
    }
   ],
   "source": [
    "# See number of examples in the JSONL file\n",
    "\n",
    "with jsonlines.open('mbpp.jsonl') as reader:\n",
    "    i = 0\n",
    "    for obj in reader:\n",
    "        i += 1\n",
    "print(\"Number of Examples: \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physics286",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
